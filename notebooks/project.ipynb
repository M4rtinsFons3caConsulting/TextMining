{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff138c00",
   "metadata": {},
   "source": [
    "# **Stock Sentiment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcc2c",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a84905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import gensim.downloader\n",
    "\n",
    "os.chdir(\"../scripts\")\n",
    "from constants import TRAIN_DATA,  TEST_DATA, LABELS\n",
    "from aux_funcs import preprocess, find_punctuated_tokens, eval_sklearn_model, eval_lstm_model, eval_transformer, eval_llm_model\n",
    "os.chdir(\"../classes\")\n",
    "from word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download NLTK resources\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17558b82",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae08bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(TRAIN_DATA)\n",
    "test_data = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd484c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3befb13e",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603d544",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset, so it is safe to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414839c3",
   "metadata": {},
   "source": [
    "### 2.1. Text Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9f181",
   "metadata": {},
   "source": [
    "#### 2.1.1. Word Count\n",
    "\n",
    "Start by spliting `text` into tokens and analysing the number of tokens in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch wordcount for each document\n",
    "train_data['word_count']  = train_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train_data[['text','word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91c13c",
   "metadata": {},
   "source": [
    "#### 2.1.2. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ee00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d683ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of text length\n",
    "sns.histplot(train_data['word_count'], bins=30)\n",
    "plt.title(\"Distribution of Text Lengths (raw text)\")\n",
    "plt.xlabel(\"Length of text\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520d4697",
   "metadata": {},
   "source": [
    "Considering the table and plot above, it is evident that some rows have very few words. Below, is a deeper exploration of these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc75d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking records with 3 words or less\n",
    "train_data[train_data['word_count'] <= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ca4e5",
   "metadata": {},
   "source": [
    "Looking at the records with 3 or less words, most belong to the Neutral category (label = 2). Since there is an overrepresentation of this class in the dataset, below the records above belonging to the Neutral category are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[~((train_data['word_count'] <= 3) & (train_data['label'] == 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking word frequency\n",
    "all_words = ' '.join(train_data['text']).split()\n",
    "freq = pd.Series(all_words).value_counts()\n",
    "freq.sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51294f0c",
   "metadata": {},
   "source": [
    "From the table above, \"the\" and \"The\" are both words in the top 10 - this could indicate a beneficial effect of lowercasing the 'text' feature.<br>\n",
    "Also, \"-\" is a very common symbol which has no meaning and should be removed from the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90466709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the word frequencies count\n",
    "x_labels = freq.index[0:10]\n",
    "values = freq[:10]\n",
    "plt.bar(x_labels, values, align='center', alpha=0.5)\n",
    "plt.xticks(x_labels)\n",
    "plt.ylabel('Frequencies')\n",
    "plt.title('Words')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd55fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word cloud from the text feature\n",
    "raw_text = ' '.join(train_data['text'].fillna('')).lower()\n",
    "raw_wc = WordCloud(width=800, height=400, background_color='white').generate(raw_text)\n",
    "plt.imshow(raw_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud (Raw Text)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5688652",
   "metadata": {},
   "source": [
    "### 2.2. Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of label\n",
    "sns.countplot(data=train_data, x='label')\n",
    "plt.title(\"Distribution of label\")\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(y='label', data=train_data, width=0.3)\n",
    "\n",
    "plt.title('Boxplot of Label', fontsize=16)\n",
    "plt.ylabel('Label', fontsize=12)\n",
    "plt.xlabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbadf24f",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining stop words\n",
    "stop = set(stopwords.words('english'))\n",
    "# Initializing Lemmatizer and Stemmer\n",
    "lemma = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed76e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(\n",
    "    lambda x: preprocess(\n",
    "        text=x\n",
    "        ,keep_ticker=False\n",
    "        ,keep_url=False\n",
    "        ,stopwords=stop\n",
    "        ,lemmatizer=lemma\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fa67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['text'] = test_data['text'].apply(\n",
    "    lambda x: preprocess(\n",
    "        text=x\n",
    "        ,keep_ticker=False\n",
    "        ,keep_url=False\n",
    "        ,stopwords=stop\n",
    "        ,lemmatizer=lemma\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a76342f",
   "metadata": {},
   "source": [
    "### 3.1. Rechecking the Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa12041",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(train_data['text']).split()\n",
    "freq = pd.Series(all_words).value_counts()\n",
    "freq.sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e12b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "x_labels = freq.index[0:10]\n",
    "values = freq[:10]\n",
    "\n",
    "plt.bar(x_labels, values, align='center', alpha=0.5)\n",
    "plt.ylabel('Frequencies')\n",
    "plt.title('Top 10 Words')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with encoding errors\n",
    "exceptions = find_punctuated_tokens(train_data['text'])\n",
    "\n",
    "pattern = r'(?:' + '|'.join(re.escape(word) for word in exceptions) + r')'\n",
    "\n",
    "train_data = train_data[~train_data['text'].str.contains(pattern, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63adb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud\n",
    "raw_text = ' '.join(train_data['text'].fillna('')).lower()\n",
    "raw_wc = WordCloud(width=800, height=400, background_color='white').generate(raw_text)\n",
    "plt.imshow(raw_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud (Raw Text)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc05193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dependent and independent features\n",
    "# Train\n",
    "X_train = train_data['text']\n",
    "y_train = train_data['label']\n",
    "# Test\n",
    "X_test = test_data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a3245",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e79d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "bow = CountVectorizer(binary=True)  # using binary=True, because working with short text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "emb_size = 100\n",
    "w2v_model = gensim.downloader.load(f'glove-twitter-{emb_size}')\n",
    "w2v = Word2Vec(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer\n",
    "transf_model = \"cardiffnlp/twitter-roberta-base-sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4bd11",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfedfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa742401",
   "metadata": {},
   "source": [
    "### 5.1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10, metric='cosine', weights='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e22d110",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_true_all, y_pred_all = eval_sklearn_model(\n",
    "    vectorizer=bow\n",
    "    ,classifier=knn\n",
    "    ,skf=skf\n",
    "    ,X_train=X_train\n",
    "    ,y_train=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall classification report across all folds:\\n\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4, target_names=LABELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS.keys(), yticklabels=LABELS.keys())\n",
    "plt.xlabel('Predicted', labelpad=15)\n",
    "plt.ylabel('True', labelpad=15)\n",
    "plt.title('Confusion Matrix (KNN Bag of Words)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f0594",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_true_all, y_pred_all = eval_sklearn_model(\n",
    "    vectorizer=w2v\n",
    "    ,classifier=knn\n",
    "    ,skf=skf\n",
    "    ,X_train=X_train\n",
    "    ,y_train=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall classification report across all folds:\\n\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4, target_names=LABELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS.keys(), yticklabels=LABELS.keys())\n",
    "plt.xlabel('Predicted', labelpad=15)\n",
    "plt.ylabel('True', labelpad=15)\n",
    "plt.title('Confusion Matrix (KNN Word2Vec)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45668d5",
   "metadata": {},
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391825c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_true_all, y_pred_all = eval_transformer(\n",
    "    transformer=transf_model\n",
    "    ,objective='feature-extraction'\n",
    "    ,skf=skf\n",
    "    ,X_train=X_train\n",
    "    ,y_train=y_train\n",
    "    ,classifier=knn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall classification report across all folds:\\n\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4, target_names=LABELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40973826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS.keys(), yticklabels=LABELS.keys())\n",
    "plt.xlabel('Predicted', labelpad=15)\n",
    "plt.ylabel('True', labelpad=15)\n",
    "plt.title('Confusion Matrix (KNN Transformer)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5212f90",
   "metadata": {},
   "source": [
    "### 5.2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7de73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_all, y_pred_all, lstm_history = eval_lstm_model(\n",
    "    vectorizer=w2v_model\n",
    "    ,emb_size=emb_size\n",
    "    ,skf=skf\n",
    "    ,X_train=X_train\n",
    "    ,y_train=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall classification report across all folds:\\n\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4, target_names=LABELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962db486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS.keys(), yticklabels=LABELS.keys())\n",
    "plt.xlabel('Predicted', labelpad=15)\n",
    "plt.ylabel('True', labelpad=15)\n",
    "plt.title('Confusion Matrix (LSTM)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991540ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for fold_idx, history in enumerate(lstm_history):\n",
    "    df_fold = pd.DataFrame(history.history)\n",
    "    df_fold['epoch'] = range(1, len(df_fold) + 1)\n",
    "    df_fold['fold'] = fold_idx  # add fold index column\n",
    "    # Reorder columns so epoch and fold come first (optional)\n",
    "    cols = ['fold', 'epoch'] + [col for col in df_fold.columns if col not in ('fold', 'epoch')]\n",
    "    df_fold = df_fold[cols]\n",
    "    df_list.append(df_fold)\n",
    "\n",
    "# Concatenate all folds into a single DataFrame\n",
    "df_history = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Show head\n",
    "df_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42530292",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "epochs = sorted(df_history['epoch'].unique())\n",
    "train_means = []\n",
    "val_means = []\n",
    "train_stds = []\n",
    "val_stds = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    epoch_data = df_history[df_history['epoch'] == epoch]\n",
    "    train_acc = epoch_data['accuracy']\n",
    "    val_acc = epoch_data['val_accuracy']\n",
    "    \n",
    "    train_means.append(train_acc.mean())\n",
    "    val_means.append(val_acc.mean())\n",
    "    train_stds.append(train_acc.std())\n",
    "    val_stds.append(val_acc.std())\n",
    "\n",
    "train_means = np.array(train_means)\n",
    "val_means = np.array(val_means)\n",
    "train_stds = np.array(train_stds)\n",
    "val_stds = np.array(val_stds)\n",
    "\n",
    "plt.plot(epochs, train_means, label='Train Mean Accuracy')\n",
    "plt.fill_between(epochs, train_means - train_stds, train_means + train_stds, alpha=0.2)\n",
    "\n",
    "plt.plot(epochs, val_means, label='Val Mean Accuracy')\n",
    "plt.fill_between(epochs, val_means - val_stds, val_means + val_stds, alpha=0.2)\n",
    "\n",
    "# Calculate min and max across both train and val means\n",
    "y_min = min(min(train_means), min(val_means)) - 0.1\n",
    "y_max = max(max(train_means), max(val_means)) + 0.1\n",
    "\n",
    "# Prevent y_min from going below 0\n",
    "y_min = max(y_min, 0)\n",
    "\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.title('Mean Model Accuracy Across Folds')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61336e89",
   "metadata": {},
   "source": [
    "### 5.3. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75729bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_true_all, y_pred_all = eval_transformer(\n",
    "    transformer=transf_model\n",
    "    ,objective='sentiment-analysis'\n",
    "    ,skf=skf\n",
    "    ,X_train=X_train\n",
    "    ,y_train=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall classification report across all folds:\\n\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4, target_names=LABELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS.keys(), yticklabels=LABELS.keys())\n",
    "plt.xlabel('Predicted', labelpad=15)\n",
    "plt.ylabel('True', labelpad=15)\n",
    "plt.title('Confusion Matrix (KNN Transformer)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c8aeaa",
   "metadata": {},
   "source": [
    "### 5.4. Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant that performs sentiment analysis.\n",
    "\n",
    "Your task is to analyze the overall sentiment of a given sentence or text.\n",
    "\n",
    "For each input, classify the sentiment as one of the following single digits ONLY:\n",
    "- 0: Bearish (negative sentiment)\n",
    "- 1: Bullish (positive sentiment)\n",
    "- 2: Neutral sentiment\n",
    "\n",
    "Respond ONLY with a single digit (0, 1, or 2), with no extra text or explanation.\n",
    "\n",
    "Examples:\n",
    "- 'JPMorgan reels in expectations on Beyond Meat' → 0\n",
    "- 'Dougherty & Company starts at Buy' → 1\n",
    "- 'Analysts React To FCC Decision On Intelsat C-Band Spectrum Auction' → 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_true_all, y_pred_all = eval_llm_model(\n",
    "    model=\"tiiuae/falcon-7b-instruct\"\n",
    "    ,skf=skf\n",
    "    ,X_train=X_train\n",
    "    ,y_train=y_train\n",
    "    ,system_message=system_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bad47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall classification report across all folds:\\n\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4, target_names=LABELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88323449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS.keys(), yticklabels=LABELS.keys())\n",
    "plt.xlabel('Predicted', labelpad=15)\n",
    "plt.ylabel('True', labelpad=15)\n",
    "plt.title('Confusion Matrix (KNN Transformer)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Review code; Complete aux_funcs.py 'analyze_sentiment'; Implement extra feature engineering (for extra points); Implement extra classification model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
