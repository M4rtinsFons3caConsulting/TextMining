{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff138c00",
   "metadata": {},
   "source": [
    "# **Stock Sentiment Analysis – Model Evaluation and Testing**\n",
    "\n",
    "This notebook investigates various machine learning techniques and models for sentiment analysis of stock-related tweets, with the objective of identifying the most effective model for accurate sentiment prediction. Its companion notebook — see TK — applies the selected model to the problem context to generate final predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcc2c",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a84905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nottoriousgg/miniconda3/envs/tm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-15 21:56:16.711179: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-15 21:56:16.724675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750020976.741367  351557 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750020976.747516  351557 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750020976.759502  351557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750020976.759528  351557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750020976.759530  351557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750020976.759531  351557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-15 21:56:16.765185: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Local Scripts\n",
    "os.chdir(\"../scripts\")\n",
    "\n",
    "# Constants\n",
    "from constants import (\n",
    "    TRAIN_DATA, \n",
    "    TEST_DATA, \n",
    "    LABELS, \n",
    "    DATA_DIR,\n",
    "    NLTK_DATA,\n",
    "    GENSIM_DATA\n",
    ") #type: ignore\n",
    "\n",
    "# Auxiliaries\n",
    "from aux_funcs import (\n",
    "    find_punctuated_tokens, \n",
    "    eval_sklearn_model, \n",
    "    eval_lstm_model,\n",
    "    eval_llm_model, \n",
    "    eval_transformer\n",
    ") #type: ignore\n",
    "\n",
    "# Data Preprocessor\n",
    "# from preprocessor import preprocess #type: ignore\n",
    "\n",
    "# Local Classes\n",
    "# os.chdir(\"../classes\")\n",
    "# from classes import W2VVectorizer, CLSVectorizer, BERTVectorizer\n",
    "\n",
    "# Standard Data Visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Wordclound Visualization\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "# Modelling and modelling metrics\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Natural Language ToolKit\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import SnowballStemmer\n",
    "#from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# General Similarity - NLP - Pre-trained Models\n",
    "# from gensim.models import Word2Vec\n",
    "# import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download if not data not found\n",
    "# if not os.path.isdir(NLTK_DATA):\n",
    "#     nltk.download('stopwords', download_dir=NLTK_DATA)\n",
    "#     nltk.download('wordnet', download_dir=NLTK_DATA)\n",
    "\n",
    "# nltk.data.path.append(NLTK_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17558b82",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae08bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(TRAIN_DATA)\n",
    "# test_data = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbadf24f",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = {\n",
    "#     \"fix_acronyms\": True,\n",
    "#     \"delete_spaces\": True,\n",
    "#     \"demojify\": True,\n",
    "#     \"clean_ticker\":True,\n",
    "#     \"keep_ticker\": True,\n",
    "#     \"anonymize_ticker\": True,\n",
    "#     \"clean_url\": True,\n",
    "#     \"keep_url\": True,\n",
    "#     \"clean_handles\": True,\n",
    "#     \"keep_handle\": True,\n",
    "#     \"clean_hashtags\": True,\n",
    "#     \"keep_hashtag\": True,\n",
    "#     \"clean_prices\": False,\n",
    "#     \"remove_punctuation\": True,\n",
    "#     \"remove_special_chars\": True,\n",
    "#     \"remove_stopwords\": False,\n",
    "#     \"lemmatize_text\": False,\n",
    "#     \"stem_text\": False,\n",
    "#     \"remove_dates_with_search\": False,\n",
    "#     \"clean_remaining_date_time\": False,\n",
    "#     \"convert_percentage_changes\": False,\n",
    "#     \"remove_contractions\": False,\n",
    "#     \"remove_possessives\": False,\n",
    "#     \"remove_locations\": False,\n",
    "#     \"remove_all_integers\": False,\n",
    "#     \"to_lower\": False\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed76e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply preprocessing\n",
    "# train_data['text'] = preprocess(\n",
    "#     corpus=train_data['text'],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ff1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply preprocessing\n",
    "# test_data['text'] = preprocess(\n",
    "#     corpus=test_data['text']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export preprocessed data\n",
    "# train_data.to_csv(f'{DATA_DIR}/train_llm_optimized.csv', sep=',', index=False)\n",
    "# test_data.to_csv(f'{DATA_DIR}/test_llm_optimized.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4751be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign datasets\n",
    "train_data = pd.read_csv(f'{DATA_DIR}/train_llm_optimized.csv')\n",
    "test_data = pd.read_csv(f'{DATA_DIR}/train_llm_optimized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with empty string\n",
    "train_data['text'] = train_data['text'].fillna('')\n",
    "test_data['text'] = test_data['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with encoding errors\n",
    "exceptions = find_punctuated_tokens(train_data['text'])\n",
    "pattern = r'(?:' + '|'.join(re.escape(word) for word in exceptions) + r')'\n",
    "train_data = train_data[~train_data['text'].str.contains(pattern, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc05193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dependent and independent features\n",
    "train_data = train_data.sample(n=100)\n",
    "# Train\n",
    "X_train = train_data['text']\n",
    "y_train = train_data['label']\n",
    "\n",
    "# Test\n",
    "X_test = test_data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4bd11",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfedfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=5\n",
    "    ,shuffle=True\n",
    "    ,random_state=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c8aeaa",
   "metadata": {},
   "source": [
    "### 5.5. Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\" You are a financial sentiment analysis engine.  \n",
    "\n",
    "Your task is to classify the sentiment of financial tweets as:  \n",
    "  0 = Bearish (negative sentiment)  \n",
    "  1 = Bullish (positive sentiment)  \n",
    "  2 = Neutral  \n",
    "\n",
    "Respond with **only a single digit (0, 1, or 2)**.  \n",
    "\n",
    "Note: In the training data, sentiment labels are distributed approximately as follows:  \n",
    "  - 15% Bearish  \n",
    "  - 25% Bullish  \n",
    "  - 60% Neutral  \n",
    "\n",
    "\n",
    "This distribution is believed to reflect the real-world proportions of financial tweet sentiment. \n",
    "Keep this in mind when interpreting ambiguous or mixed signals, as it is believed that the inputs \n",
    "provided to you will also fall under that distribution — avoid overconfident or unwarranted sentiment assignments.\n",
    "\n",
    "**Examples:**  \n",
    "  \"JPMorgan reels in expectations on Beyond Meat\" → 0  \n",
    "  \"Dougherty & Company starts at Buy\" → 1  \n",
    "  \"Analysts React To FCC Decision On Intelsat C-Band Spectrum Auction\" → 2  \n",
    "\n",
    "[INPUT]  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now evaluating please hold...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_true_all, y_pred_all = eval_llm_model(\n",
    "    model=\"tiiuae/falcon-7b-instruct\"\n",
    "    ,skf=skf\n",
    "    ,X_train=X_train\n",
    "    ,y_train=y_train\n",
    "    ,system_message=system_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bad47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall classification report across all folds:\\n\")\n",
    "print(classification_report(y_true_all, y_pred_all, digits=4, target_names=LABELS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88323449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS.keys(), yticklabels=LABELS.keys())\n",
    "plt.xlabel('Predicted', labelpad=15)\n",
    "plt.ylabel('True', labelpad=15)\n",
    "plt.title('Confusion Matrix (Language Model)', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
